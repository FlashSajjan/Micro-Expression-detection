{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f433e912-4ba0-4f72-93e7-64731085e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Flatten, Dense, Dropout, concatenate, add\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8468f84-8d62-49ba-a0a6-6e3d00af62f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenCV Haar Cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "742097fe-8277-4a84-9694-11ef66a45978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel columns: Index(['Subject', 'Filename', 'Unnamed: 2', 'OnsetF', 'ApexF1', 'ApexF2',\n",
      "       'OffsetF', 'Unnamed: 7', 'Onset', 'Total', 'AU', 'Emotion'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Data Loading and Preprocessing from Excel\n",
    "base_dataset_path = \"E:/FacialMicroExpression/data\"\n",
    "excel_file_path = \"Section A.xls\"\n",
    "output_size = (112, 112)\n",
    "motion_threshold = 1e-3\n",
    "\n",
    "# Read the Excel file to get the emotion labels for each sub folder\n",
    "def load_data_from_excel(excel_file_path):\n",
    "    \"\"\"Reads the Excel file containing filenames and labels.\"\"\"\n",
    "    data = pd.read_excel(excel_file_path)\n",
    "    return data\n",
    "print(\"Excel columns:\", load_data_from_excel(excel_file_path).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ffb715-6227-4f1a-8457-d7bb985ce5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   Subject Filename  Unnamed: 2  OnsetF  ApexF1 ApexF2 OffsetF  Unnamed: 7  \\\n",
      "0        1  EP01_12         NaN      73      81      \\      91         NaN   \n",
      "1        1  EP01_12         NaN     163     169      \\     177         NaN   \n",
      "2        1   EP01_5         NaN     113     121    125     133         NaN   \n",
      "3        1   EP01_8         NaN      67      75      \\      81         NaN   \n",
      "4        1   EP03_1         NaN      79      91     95     105         NaN   \n",
      "\n",
      "        Onset       Total  AU     Emotion  \n",
      "0  150.000000  316.666667   4       tense  \n",
      "1  116.666667         250   4       tense  \n",
      "2  150.000000         350  12   happiness  \n",
      "3  150.000000         250  14  repression  \n",
      "4  216.666667         450  17  repression  \n",
      "\n",
      "Cleaned Data:\n",
      "  Subject Filename  Unnamed: 2  OnsetF  ApexF1 ApexF2 OffsetF  Unnamed: 7  \\\n",
      "0       1  ep01_12         NaN      73      81      \\      91         NaN   \n",
      "1       1  ep01_12         NaN     163     169      \\     177         NaN   \n",
      "2       1   ep01_5         NaN     113     121    125     133         NaN   \n",
      "3       1   ep01_8         NaN      67      75      \\      81         NaN   \n",
      "4       1   ep03_1         NaN      79      91     95     105         NaN   \n",
      "\n",
      "        Onset       Total  AU     Emotion  \n",
      "0  150.000000  316.666667   4       tense  \n",
      "1  116.666667         250   4       tense  \n",
      "2  150.000000         350  12   happiness  \n",
      "3  150.000000         250  14  repression  \n",
      "4  216.666667         450  17  repression  \n",
      "\n",
      "Unique Emotions:\n",
      "['tense' 'happiness' 'repression' 'disgust' 'surprise' 'comtempt' 'fear'\n",
      " 'sadness']\n",
      "\n",
      "Unique Subjects:\n",
      "19\n",
      "\n",
      "Unique Filenames:\n",
      "120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Filename</th>\n",
       "      <th>OnsetF</th>\n",
       "      <th>ApexF1</th>\n",
       "      <th>ApexF2</th>\n",
       "      <th>OffsetF</th>\n",
       "      <th>Onset</th>\n",
       "      <th>Total</th>\n",
       "      <th>AU</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ep01_12</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>\\</td>\n",
       "      <td>91</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>316.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>tense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ep01_12</td>\n",
       "      <td>163</td>\n",
       "      <td>169</td>\n",
       "      <td>\\</td>\n",
       "      <td>177</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>250</td>\n",
       "      <td>4</td>\n",
       "      <td>tense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ep01_5</td>\n",
       "      <td>113</td>\n",
       "      <td>121</td>\n",
       "      <td>125</td>\n",
       "      <td>133</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>350</td>\n",
       "      <td>12</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ep01_8</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>\\</td>\n",
       "      <td>81</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>250</td>\n",
       "      <td>14</td>\n",
       "      <td>repression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ep03_1</td>\n",
       "      <td>79</td>\n",
       "      <td>91</td>\n",
       "      <td>95</td>\n",
       "      <td>105</td>\n",
       "      <td>216.666667</td>\n",
       "      <td>450</td>\n",
       "      <td>17</td>\n",
       "      <td>repression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject Filename  OnsetF  ApexF1 ApexF2 OffsetF       Onset       Total  AU  \\\n",
       "0       1  ep01_12      73      81      \\      91  150.000000  316.666667   4   \n",
       "1       1  ep01_12     163     169      \\     177  116.666667         250   4   \n",
       "2       1   ep01_5     113     121    125     133  150.000000         350  12   \n",
       "3       1   ep01_8      67      75      \\      81  150.000000         250  14   \n",
       "4       1   ep03_1      79      91     95     105  216.666667         450  17   \n",
       "\n",
       "      Emotion  \n",
       "0       tense  \n",
       "1       tense  \n",
       "2   happiness  \n",
       "3  repression  \n",
       "4  repression  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning and normalization\n",
    "# Path to the Excel file\n",
    "excel_file_path = \"Section A.xls\"\n",
    "\n",
    "# Load the Excel file\n",
    "data = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Display the original DataFrame for reference\n",
    "print(\"Original Data:\")\n",
    "print(data.head())\n",
    "\n",
    "# Data cleaning and normalization\n",
    "# Normalize columns: Subject, Filename, and Emotion\n",
    "data['Subject'] = data['Subject'].astype(str).str.strip().str.lower()  # Normalize Subject column\n",
    "data['Filename'] = data['Filename'].astype(str).str.strip().str.lower()  # Normalize Filename column\n",
    "data['Emotion'] = data['Emotion'].astype(str).str.strip().str.lower()  # Normalize Emotion column\n",
    "\n",
    "# Handle missing values in critical columns\n",
    "data.dropna(subset=['Subject', 'Filename', 'Emotion'], inplace=True)  # Drop rows with missing values in these columns\n",
    "\n",
    "# Remove duplicates if any (considering all columns for uniqueness)\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"\\nCleaned Data:\")\n",
    "print(data.head())\n",
    "\n",
    "# Display unique emotions for verification\n",
    "print(\"\\nUnique Emotions:\")\n",
    "print(data['Emotion'].unique())\n",
    "\n",
    "# Display the count of unique subjects and filenames for debugging\n",
    "print(\"\\nUnique Subjects:\")\n",
    "print(data['Subject'].nunique())\n",
    "print(\"\\nUnique Filenames:\")\n",
    "print(data['Filename'].nunique())\n",
    "data = data.drop(columns=['Unnamed: 2', 'Unnamed: 7'], errors='ignore')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a63e5e-d19c-4975-a65b-01886adf6fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_EP_folders(base_dataset_path, data):\n",
    "    image_data = []\n",
    "    image_labels = []\n",
    "    unmatched_folders = []\n",
    "\n",
    "    for subfolder in os.listdir(base_dataset_path):\n",
    "        subfolder_path = os.path.join(base_dataset_path, subfolder)\n",
    "\n",
    "        # Format the subject (e.g., 1 -> sub01, 2 -> sub02)\n",
    "        subject_id = subfolder.strip().lower().replace(\"sub\", \"\")  # Remove 'sub' and match\n",
    "        matching_subjects = data[data['Subject'].astype(str).str.zfill(2) == subject_id]\n",
    "\n",
    "        if not matching_subjects.empty:\n",
    "            for ep_folder in os.listdir(subfolder_path):\n",
    "                ep_folder_path = os.path.join(subfolder_path, ep_folder)\n",
    "\n",
    "                # Match ep_folder with Filename column in Excel (normalize case)\n",
    "                matching_filenames = matching_subjects[matching_subjects['Filename'].str.strip().str.lower() == ep_folder.strip().lower()]\n",
    "\n",
    "                if not matching_filenames.empty and os.path.isdir(ep_folder_path):\n",
    "                    for file_name in os.listdir(ep_folder_path):\n",
    "                        if file_name.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                            image_path = os.path.join(ep_folder_path, file_name)\n",
    "\n",
    "                            image = cv2.imread(image_path)\n",
    "                            if image is not None:\n",
    "                                resized_image = cv2.resize(image, (112, 112))\n",
    "                                image_data.append(resized_image)\n",
    "\n",
    "                                # Extract emotion label from matching row in Excel\n",
    "                                label = matching_filenames['Emotion'].values[0]\n",
    "                                image_labels.append(label)\n",
    "                else:\n",
    "                    unmatched_folders.append(ep_folder)\n",
    "        else:\n",
    "            unmatched_folders.append(subfolder)\n",
    "\n",
    "    \n",
    "    print(f\"Unique labels: {set(image_labels)}\")\n",
    "\n",
    "    return image_data, image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d79b374c-1c6c-43b3-bf0e-98890c219679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: {'sadness', 'tense', 'surprise', 'happiness', 'comtempt', 'fear', 'repression', 'disgust'}\n",
      "Image 1 shape: (112, 112, 3)\n",
      "Image 2 shape: (112, 112, 3)\n",
      "Image 3 shape: (112, 112, 3)\n",
      "Image 4 shape: (112, 112, 3)\n",
      "Image 5 shape: (112, 112, 3)\n",
      "Unique labels in the dataset: ['tense' 'happiness' 'repression' 'disgust' 'surprise' 'comtempt' 'fear'\n",
      " 'sadness']\n"
     ]
    }
   ],
   "source": [
    "image_data, image_labels = load_images_from_EP_folders(base_dataset_path, data)\n",
    "for idx, image in enumerate(image_data[:5]):  # Check first 5 images\n",
    "    print(f\"Image {idx + 1} shape: {image.shape}\")\n",
    "unique_labels = data['Emotion'].unique()\n",
    "print(f\"Unique labels in the dataset: {unique_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12a65ba8-17d2-4f94-9f6c-bd25a4cd684c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1: Label = tense\n",
      "Image 2: Label = tense\n",
      "Image 3: Label = tense\n",
      "Image 4: Label = tense\n",
      "Image 5: Label = tense\n"
     ]
    }
   ],
   "source": [
    "for i, (image, label) in enumerate(zip(image_data[:5], image_labels[:5])):  # First 5 pairs\n",
    "    print(f\"Image {i + 1}: Label = {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "73c2fc87-1c56-4e1f-8958-4b04b0eb3d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dynamic_image(frames, normalized=True):\n",
    "    \"\"\"Improved dynamic image calculation using temporal weighting\"\"\"\n",
    "    if len(frames) == 0:\n",
    "        return np.zeros((112, 112, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Convert frames to numpy array\n",
    "    frames = np.array(frames, dtype=np.float32)\n",
    "    \n",
    "    # Calculate temporal weights\n",
    "    weights = np.arange(1, len(frames)+1)\n",
    "    \n",
    "    # Compute weighted sum\n",
    "    weighted_frames = np.tensordot(weights, frames, axes=((0),(0)))\n",
    "    dynamic_image = weighted_frames / weights.sum()\n",
    "    \n",
    "    if normalized:\n",
    "        dynamic_image = cv2.normalize(dynamic_image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    return dynamic_image.astype(np.uint8)\n",
    "\n",
    "\n",
    "def _get_channel_frames(iter_frames, num_channels):\n",
    "    \"\"\" Takes a list of frames and returns a list of frame lists split by channel. \"\"\"\n",
    "    frames = [[] for channel in range(num_channels)]\n",
    "\n",
    "    for frame in iter_frames:\n",
    "        for channel_frames, channel in zip(frames, cv2.split(frame)):\n",
    "            channel_frames.append(channel.reshape((*channel.shape[0:2], 1)))\n",
    "    for i in range(len(frames)):\n",
    "        frames[i] = np.array(frames[i])\n",
    "    return frames\n",
    "\n",
    "\n",
    "# Replace with corrected version:\n",
    "def _compute_dynamic_image(frames):\n",
    "    if len(frames) == 0:\n",
    "        return np.zeros((112, 112, 1), dtype=np.uint8)\n",
    "    \n",
    "    # Simplified temporal weighting\n",
    "    weights = np.arange(1, len(frames)+1)\n",
    "    weighted_frames = np.tensordot(weights, frames, axes=((0),(0)))\n",
    "    return (weighted_frames / weights.sum()).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e6f41a24-c774-488c-bf30-835403b0c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_videos(base_dataset_path, data, output_size=(112, 112)):\n",
    "    video_data = []\n",
    "    video_labels = []\n",
    "\n",
    "    for subject_folder in os.listdir(base_dataset_path):\n",
    "        subject_path = os.path.join(base_dataset_path, subject_folder)\n",
    "        \n",
    "        if os.path.isdir(subject_path):\n",
    "            # Extract subject ID from folder name (e.g., \"sub01\" -> \"01\")\n",
    "            subject_id = subject_folder.lower().replace(\"sub\", \"\").strip()\n",
    "            \n",
    "            # Match with Excel data using both Subject and Filename\n",
    "            subject_data = data[data['Subject'].astype(str).str.lower() == subject_id]\n",
    "            \n",
    "            if not subject_data.empty:\n",
    "                for file_name in os.listdir(subject_path):\n",
    "                    if file_name.endswith('.avi'):\n",
    "                        # Extract EP code from filename (e.g., \"EP01_xxx.avi\" -> \"ep01\")\n",
    "                        video_filename = file_name.split('_')[0].lower().strip()\n",
    "                        \n",
    "                        # Find matching emotion label\n",
    "                        matching_row = subject_data[\n",
    "                            subject_data['Filename'].str.lower() == video_filename\n",
    "                        ]\n",
    "                        \n",
    "                        if not matching_row.empty:\n",
    "                            video_path = os.path.join(subject_path, file_name)\n",
    "                            cap = cv2.VideoCapture(video_path)\n",
    "                            frames = []\n",
    "                            \n",
    "                            while cap.isOpened():\n",
    "                                ret, frame = cap.read()\n",
    "                                if not ret:\n",
    "                                    break\n",
    "                                resized_frame = cv2.resize(frame, output_size)\n",
    "                                frames.append(resized_frame)\n",
    "                            \n",
    "                            cap.release()\n",
    "                            \n",
    "                            if len(frames) > 0:\n",
    "                                # Generate improved dynamic image\n",
    "                                dynamic_image = get_dynamic_image(frames)\n",
    "                                video_data.append(dynamic_image)\n",
    "                                video_labels.append(matching_row['Emotion'].values[0])\n",
    "\n",
    "    return video_data, video_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a07f9cbc-7257-44f3-9ebd-ba322e12f5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: {'tense'}\n"
     ]
    }
   ],
   "source": [
    "video_data, video_labels = load_videos(base_dataset_path, data)\n",
    "print(f\"Unique labels: {set(video_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "95e4e163-e116-418a-a39a-3dd37f5f9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save(X, y, prefix, output_size=(112, 112), batch_size=500):\n",
    "    encoder = LabelEncoder()\n",
    "    y_encoded = encoder.fit_transform(y)\n",
    "    \n",
    "    for i in range(0, len(X), batch_size):\n",
    "        X_batch = []\n",
    "        y_batch = y_encoded[i:i+batch_size]\n",
    "        \n",
    "        for img in X[i:i+batch_size]:\n",
    "            img = cv2.resize(img, output_size)\n",
    "            img_ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n",
    "            img_ycrcb[:,:,0] = cv2.equalizeHist(img_ycrcb[:,:,0])\n",
    "            img = cv2.cvtColor(img_ycrcb, cv2.COLOR_YCR_CB2BGR)\n",
    "            X_batch.append(img)\n",
    "\n",
    "        X_batch = np.array(X_batch, dtype='float32') / 255.0\n",
    "\n",
    "        np.save(f'{prefix}_X_part{i//batch_size}.npy', X_batch)\n",
    "        np.save(f'{prefix}_y_part{i//batch_size}.npy', y_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c5580077-f623-4cc2-8718-a19711e7b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_and_save(image_data, image_labels, 'image', batch_size=500)\n",
    "preprocess_and_save(video_data, video_labels, 'video', batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5e8a48ab-c627-444a-9995-76c39ab5295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "num_image_batches = len(image_data) // batch_size + (1 if len(image_data) % batch_size else 0)\n",
    "num_video_batches = len(video_data) // batch_size + (1 if len(video_data) % batch_size else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b0885518-7f60-44d9-b5ef-21af96a44a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.concatenate([np.load(f'image_X_part{i}.npy') for i in range(num_image_batches)] +\n",
    "                       [np.load(f'video_X_part{i}.npy') for i in range(num_video_batches)])\n",
    "y_all = np.concatenate([np.load(f'image_y_part{i}.npy') for i in range(num_image_batches)] +\n",
    "                       [np.load(f'video_y_part{i}.npy') for i in range(num_video_batches)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "53ae39ea-1f18-49a5-9670-a49012a8de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_all\n",
    "y = y_all\n",
    "# 1. Calculate num_classes FIRST\n",
    "num_classes = len(np.unique(y))  # Use full dataset\n",
    "\n",
    "# 2. Stratified split to preserve class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # Critical for imbalanced data\n",
    ")\n",
    "\n",
    "# 3. One-hot encode\n",
    "y_train_onehot = to_categorical(y_train, num_classes=num_classes).astype(np.float32)\n",
    "y_test_onehot = to_categorical(y_test, num_classes=num_classes).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9e45c444-7997-4b0a-b998-7cf551d50124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LearNet_Modelbuild(height=112, width=112, channels=3, classes=8):\n",
    "    im = Input(shape=(height, width, channels))\n",
    "    Conv_S = Conv2D(16, (3, 3), activation='relu', padding='same', strides=2, name='Conv_S')(im)\n",
    "\n",
    "    Conv_1_1 = Conv2D(16, (1, 1), activation='relu', padding='same', strides=2, name='Conv_1_1')(Conv_S)\n",
    "    Conv_1_2 = Conv2D(32, (3, 3), activation='relu', padding='same', strides=2, name='Conv_1_2')(Conv_1_1)\n",
    "    Conv_1_3 = Conv2D(64, (5, 5), activation='relu', padding='same', strides=2, name='Conv_1_3')(Conv_1_2)\n",
    "\n",
    "    Conv_2_1 = Conv2D(16, (1, 1), activation='relu', padding='same', strides=2, name='Conv_2_1')(Conv_S)\n",
    "    add_2_1 = add([Conv_1_1, Conv_2_1])\n",
    "    batch_r11 = BatchNormalization()(add_2_1)\n",
    "    Conv_2_2 = Conv2D(32, (3, 3), activation='relu', padding='same', strides=2, name='Conv_2_2')(batch_r11)\n",
    "    add_2_2 = add([Conv_1_2, Conv_2_2])\n",
    "    batch_r12 = BatchNormalization()(add_2_2)\n",
    "    Conv_x_2 = Conv2D(64, (5, 5), activation='relu', padding='same', strides=2, name='Conv_x_2')(batch_r12)\n",
    "\n",
    "    Conv_3_1 = Conv2D(16, (1, 1), activation='relu', padding='same', strides=2, name='Conv_3_1')(Conv_S)\n",
    "    Conv_3_2 = Conv2D(32, (3, 3), activation='relu', padding='same', strides=2, name='Conv_3_2')(Conv_3_1)\n",
    "    Conv_3_3 = Conv2D(64, (5, 5), activation='relu', padding='same', strides=2, name='Conv_3_3')(Conv_3_2)\n",
    "\n",
    "    Conv_4_1 = Conv2D(16, (1, 1), activation='relu', padding='same', strides=2, name='Conv_4_1')(Conv_S)\n",
    "    add_4_1 = add([Conv_3_1, Conv_4_1])\n",
    "    batch_r13 = BatchNormalization()(add_4_1)\n",
    "    Conv_4_2 = Conv2D(32, (3, 3), activation='relu', padding='same', strides=2, name='Conv_4_2')(batch_r13)\n",
    "    add_4_2 = add([Conv_3_2, Conv_4_2])\n",
    "    batch_r14 = BatchNormalization()(add_4_2)\n",
    "    Conv_x_4 = Conv2D(64, (5, 5), activation='relu', padding='same', strides=2, name='Conv_x_4')(batch_r14)\n",
    "\n",
    "    concta1 = concatenate([Conv_1_3, Conv_x_2, Conv_3_3, Conv_x_4])\n",
    "    batch_X = BatchNormalization()(concta1)\n",
    "\n",
    "    Conv_5_1 = Conv2D(256, (3, 3), activation='relu', padding='same', strides=2, name='Conv_5_1')(batch_X)\n",
    "\n",
    "    F1 = Flatten()(Conv_5_1)\n",
    "    FC1 = Dense(256, activation='relu')(F1)\n",
    "    drop = Dropout(0.5)(FC1)\n",
    "\n",
    "    out = Dense(classes, activation='softmax')(drop)\n",
    "\n",
    "    model = Model(inputs=[im], outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ed94cb63-ae38-4a4e-ae16-62103dad1eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_S (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │ Conv_S[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │ Conv_S[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_3_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │ Conv_S[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_4_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │ Conv_S[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Conv_1_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
       "│                               │                           │                 │ Conv_2_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Conv_3_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
       "│                               │                           │                 │ Conv_4_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_25        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ add_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_27        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ add_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │ Conv_1_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │ batch_normalization_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_3_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │ Conv_3_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_4_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │ batch_normalization_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Conv_1_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
       "│                               │                           │                 │ Conv_2_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Conv_3_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
       "│                               │                           │                 │ Conv_4_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_26        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_28        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_1_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │ Conv_1_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_x_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │ batch_normalization_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_3_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │ Conv_3_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_x_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │ batch_normalization_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Conv_1_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
       "│                               │                           │                 │ Conv_x_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
       "│                               │                           │                 │ Conv_3_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
       "│                               │                           │                 │ Conv_x_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_29        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_5_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ batch_normalization_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Conv_5_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,832</span> │ flatten_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m3\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_S (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m448\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_1_1 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m272\u001b[0m │ Conv_S[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_2_1 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m272\u001b[0m │ Conv_S[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_3_1 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m272\u001b[0m │ Conv_S[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_4_1 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m272\u001b[0m │ Conv_S[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_20 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │ Conv_1_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
       "│                               │                           │                 │ Conv_2_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_22 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │ Conv_3_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
       "│                               │                           │                 │ Conv_4_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_25        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │              \u001b[38;5;34m64\u001b[0m │ add_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_27        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │              \u001b[38;5;34m64\u001b[0m │ add_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_1_2 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m4,640\u001b[0m │ Conv_1_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_2_2 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m4,640\u001b[0m │ batch_normalization_25[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_3_2 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m4,640\u001b[0m │ Conv_3_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_4_2 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m4,640\u001b[0m │ batch_normalization_27[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_21 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │ Conv_1_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
       "│                               │                           │                 │ Conv_2_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_23 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │ Conv_3_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
       "│                               │                           │                 │ Conv_4_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_26        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │ add_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_28        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │ add_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_1_3 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m51,264\u001b[0m │ Conv_1_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_x_2 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m51,264\u001b[0m │ batch_normalization_26[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_3_3 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m51,264\u001b[0m │ Conv_3_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_x_4 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m51,264\u001b[0m │ batch_normalization_28[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_5 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ Conv_1_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
       "│                               │                           │                 │ Conv_x_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
       "│                               │                           │                 │ Conv_3_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
       "│                               │                           │                 │ Conv_x_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_29        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Conv_5_1 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │ batch_normalization_29[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ Conv_5_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │       \u001b[38;5;34m1,048,832\u001b[0m │ flatten_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                 │           \u001b[38;5;34m2,056\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,867,528</span> (7.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,867,528\u001b[0m (7.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,866,824</span> (7.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,866,824\u001b[0m (7.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LearNet_Modelbuild()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1378a709-72ef-446c-9798-df28d9749217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_lighting_normalization(img):\n",
    "    \"\"\"Adaptive normalization with smart contrast handling\"\"\"\n",
    "    # Convert to LAB color space\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l_channel = lab[:, :, 0]\n",
    "\n",
    "    # Ensure L-channel is uint8\n",
    "    if l_channel.dtype != np.uint8:\n",
    "        l_channel = (l_channel * 255).astype(np.uint8) if l_channel.max() <= 1.0 else l_channel.astype(np.uint8)\n",
    "\n",
    "    # Calculate histogram clipping dynamically\n",
    "    hist = cv2.calcHist([l_channel], [0], None, [256], [0, 256])\n",
    "    hist_norm = hist.ravel() / hist.sum()\n",
    "    q = np.cumsum(hist_norm)\n",
    "    clip_limit = 1.5 + (np.where(q > 0.9)[0][0] / 255 * 4)\n",
    "\n",
    "    # Apply CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))\n",
    "    lab[:, :, 0] = clahe.apply(l_channel)\n",
    "\n",
    "    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f5e0cf23-da82-4f5f-8eb6-7bc2d05f5d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def realistic_lighting_augmentation(img):\n",
    "    gamma = np.clip(np.random.normal(1.0, 0.4), 0.4, 2.2)\n",
    "    table = np.array([((i / 255.0) ** (1 / gamma)) * 255 for i in range(256)]).astype(\"uint8\")\n",
    "    img = cv2.LUT(img, table)\n",
    "\n",
    "    alpha = np.random.uniform(0.8, 1.3)\n",
    "    beta = np.random.uniform(-30, 30)\n",
    "    img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "\n",
    "    if np.random.rand() < 0.3:\n",
    "        rows, cols = img.shape[:2]\n",
    "        pts = np.array([[\n",
    "            [cols * np.random.uniform(0, 0.3), rows * np.random.uniform(0, 0.3)],\n",
    "            [cols * np.random.uniform(0.7, 1), rows * np.random.uniform(0, 0.3)],\n",
    "            [cols * np.random.uniform(0.6, 1), rows * np.random.uniform(0.7, 1)],\n",
    "            [cols * np.random.uniform(0, 0.4), rows * np.random.uniform(0.7, 1)]\n",
    "        ]])\n",
    "        shadow_mask = np.zeros_like(img, dtype=np.uint8)\n",
    "        shadow_value = np.random.uniform(50, 100)\n",
    "        cv2.fillPoly(shadow_mask, pts.astype(int), (shadow_value,) * 3)\n",
    "        img = cv2.addWeighted(img, 1.0, shadow_mask, 0.5, 0)\n",
    "\n",
    "    noise = np.random.normal(0, np.random.uniform(1, 8), img.shape).astype(np.int16)\n",
    "    img = np.clip(img.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386bc222-84c7-484d-a86c-43da0364c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(images):\n",
    "    processed = [optimized_lighting_normalization(img) for img in images]\n",
    "    processed = np.array(processed).astype(np.float32) / 255.0\n",
    "    return np.mean(processed, axis=(0, 1, 2)), np.std(processed, axis=(0, 1, 2))\n",
    "\n",
    "dataset_mean, dataset_std = compute_stats(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cd596f-32db-4d38-aeb6-71087ae8e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unified Preprocessing:\n",
    "def custom_preprocessing(img):\n",
    "    # Convert to [0,255] range first\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    \n",
    "    # CLAHE on L channel\n",
    "    lab = cv2.cvtColor(img_uint8, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    lab = cv2.merge([clahe.apply(l), a, b])\n",
    "    img = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    # Standardize\n",
    "    return (img.astype(np.float32) - dataset_mean) / dataset_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "dcbf9ed5-b628-48e2-a92a-30f7b7548c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=custom_preprocessing,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=[0.85, 1.15],\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.7, 1.4),\n",
    "    channel_shift_range=15.0,\n",
    "    fill_mode='constant',\n",
    "    cval=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d029d5e5-6575-45d2-ada7-8a75c0aa6ab0",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.73 GiB for an array with shape (26575, 112, 112, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[169], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fix generators:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Convert to float32 before training\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      4\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      5\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow(\n\u001b[0;32m      6\u001b[0m     X_train, y_train_onehot,  \u001b[38;5;66;03m# Use one-hot labels\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m      8\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.73 GiB for an array with shape (26575, 112, 112, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "# Fix generators:\n",
    "# Convert to float32 before training\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "train_generator = train_datagen.flow(\n",
    "    X_train, y_train_onehot,  # Use one-hot labels\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow(\n",
    "    X_test, y_test_onehot,    # Use one-hot labels\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f225749a-1ab4-4bd1-baec-1c576aa3ef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use original labels (not one-hot)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "63129a49-8c54-4a05-accd-00c043cb36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Checkpoint Callback\n",
    "callbacks = ModelCheckpoint('best_model.keras', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bd4c131c-248e-4c16-8f0a-7f05de0cafab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping Callback - Stops training if validation loss doesn't improve for 5 epochs\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=40,  # Stop training if no improvement for 5 epochs\n",
    "    restore_best_weights=True,\n",
    "    min_delta=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5ccc724e-6d08-4dd4-ba67-7c9d497b6013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_116']\n",
      "Received: inputs=Tensor(shape=(None, 112, 112, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float64, tf.float32), but the yielded element was (array([[[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       ...,\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]]], dtype=float32), array([[0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 1., 0.]])).\nTraceback (most recent call last):\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 204, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\", line 237, in flatten_up_to\n    return nest_util.flatten_up_to(\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1541, in flatten_up_to\n    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1570, in _tf_data_flatten_up_to\n    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1427, in _tf_data_assert_shallow_structure\n    raise ValueError(\n\nValueError: The two structures don't have the same sequence length. Input structure has length 2, while shallow structure has length 3.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 206, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float64, tf.float32), but the yielded element was (array([[[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       ...,\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]]], dtype=float32), array([[0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 1., 0.]])).\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_multi_step_on_iterator_30951]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[152], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      2\u001b[0m     train_datagen\u001b[38;5;241m.\u001b[39mflow(X_train, y_train_onehot, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m),\n\u001b[0;32m      3\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[0;32m      4\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test_onehot),\n\u001b[0;32m      5\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mclass_weights,\n\u001b[0;32m      6\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float64, tf.float32), but the yielded element was (array([[[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       ...,\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]]], dtype=float32), array([[0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 1., 0.]])).\nTraceback (most recent call last):\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 204, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\", line 237, in flatten_up_to\n    return nest_util.flatten_up_to(\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1541, in flatten_up_to\n    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1570, in _tf_data_flatten_up_to\n    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1427, in _tf_data_assert_shallow_structure\n    raise ValueError(\n\nValueError: The two structures don't have the same sequence length. Input structure has length 2, while shallow structure has length 3.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 206, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float64, tf.float32), but the yielded element was (array([[[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       ...,\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]],\n\n\n       [[[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        ...,\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]],\n\n        [[-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         ...,\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962],\n         [-2.1171687, -2.0349627, -1.8036962]]]], dtype=float32), array([[0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 1., 0.]])).\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_multi_step_on_iterator_30951]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_datagen.flow(X_train, y_train_onehot, batch_size=32),\n",
    "    epochs=200,\n",
    "    validation_data=(X_test, y_test_onehot),\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eb09327-ba0b-4e65-bca7-03348175f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the model\n",
    "def save_model(model, filename='best_model.h5'):\n",
    "    model.save(filename)\n",
    "    print(f\"Model saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9b2791f-d178-487a-b9c1-fd9c27306d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as lear_net.h5\n"
     ]
    }
   ],
   "source": [
    "save_model(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9456a8f5-1e82-45f8-a361-94cff4b7b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model (after training)\n",
    "def load_trained_model(filename='lear_net.h5'):\n",
    "    model = load_model(filename)\n",
    "    print(f\"Model loaded from {filename}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc7f4c2b-6fb8-461b-918b-31c8cf880123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test loss: {loss}\")\n",
    "    print(f\"Test accuracy: {accuracy}\")\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "789a927d-0963-4109-b21a-14ab4b77f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the micro facial expression for a single image\n",
    "def predict_expression(image_path, model, target_size=(112, 112)):\n",
    "    # Load and preprocess the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, target_size)  # Resize to match model input\n",
    "    image = img_to_array(image) / 255.0  # Normalize the image\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Predict using the model\n",
    "    prediction = model.predict(image)\n",
    "\n",
    "    # Get the predicted label (assuming the labels are one-hot encoded)\n",
    "    predicted_label = np.argmax(prediction, axis=1)[0]\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8162daf6-fb3d-4a3b-a3dd-9ee76023a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping Numerical Prediction to Emotion:\n",
    "def get_emotion_label(predicted_label, label_encoder):\n",
    "    emotion = label_encoder.classes_[predicted_label]\n",
    "    return emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74766deb-a456-46c5-855f-3fd5fa1de080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Prediction on a Single Image:\n",
    "def test_single_prediction(image_path, model, label_encoder, target_size=(112, 112)):\n",
    "    predicted_label = predict_expression(image_path, model, target_size)\n",
    "    emotion = get_emotion_label(predicted_label, label_encoder)\n",
    "    print(f\"Predicted Micro Expression: {emotion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dad392d8-b2f1-48fa-840a-62c4d0edb186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion labels (these are the 8 emotions you're interested in)\n",
    "emotion_labels = ['tense', 'happiness', 'repression', 'disgust', 'surprise', 'comtempt', 'fear', 'sadness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b019f3cd-9411-4a77-85af-75bcd47a05bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LabelEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(emotion_labels)  # Fit on the 8 emotion labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db01eee2-468f-41bd-bc2b-6d683fd3346d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from lear_net.h5\n"
     ]
    }
   ],
   "source": [
    "lear_net=load_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0ba38c6-347b-4551-aa42-64ae53bb49a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.9490 - loss: 0.1192\n",
      "Test loss: 0.1387115716934204\n",
      "Test accuracy: 0.9507211446762085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1387115716934204, 0.9507211446762085)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(lear_net, X_test, y_test_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b275a23c-0943-47d4-9a17-332128fde563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "image_path =\"C:/Users/Sajjan/Downloads/happy.jpg\"\n",
    "# Load the image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "if image is None:\n",
    "    print(f\"Error: Image not found or unable to load at {image_path}\")\n",
    "else:\n",
    "    print(\"Image loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c22cc01a-736e-49f9-8606-e374127cc818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted Micro Expression: tense\n"
     ]
    }
   ],
   "source": [
    "#Test on a Single Image:\n",
    "#image_path = \"FacialMicroExpression/data/sub01/EP01_5/EP01_5-2.jpg\"\n",
    "prediction=test_single_prediction(image_path, lear_net, label_encoder)\n",
    "predicted_index = np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48aeca9-cf86-4589-8121-445c4dcf49c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
